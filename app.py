import streamlit as st
import os
import time
import uuid
import pandas as pd
from google import genai
from google.genai.errors import APIError

# --- ìƒìˆ˜ ë° ì„¤ì • ---

# í˜„ì¬ ì‹œê°„ì„ ê¸°ë°˜ìœ¼ë¡œ ê³ ìœ í•œ ì„¸ì…˜ IDë¥¼ ìƒì„±
if 'session_id' not in st.session_state:
    st.session_state.session_id = str(uuid.uuid4())
    st.session_state.start_time = time.strftime("%Y-%m-%d %H:%M:%S")

# Gemini ëª¨ë¸ ëª©ë¡ (exp ëª¨ë¸ ì œì™¸)
AVAILABLE_MODELS = [
    "gemini-2.5-flash",
    "gemini-2.0-flash",
    "gemini-2.5-pro",
    "gemini-2.0-pro",
]

# LLM ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ (í•œêµ­ì–´, ê³ ê° ì‘ëŒ€ íŠ¹í™”)
SYSTEM_PROMPT = """
ë‹¹ì‹ ì€ ì‡¼í•‘ëª° êµ¬ë§¤ ê³¼ì •ì—ì„œ ë¶ˆí¸ì„ ê²ªì€ ê³ ê°ì„ ì‘ëŒ€í•˜ëŠ” ë§¤ìš° ì „ë¬¸ì ì´ê³  ì¹œì ˆí•œ ê³ ê° ì‘ëŒ€ ì±—ë´‡ì…ë‹ˆë‹¤.
ë‹¤ìŒ ê·œì¹™ì„ ì—„ê²©íˆ ì¤€ìˆ˜í•˜ì—¬ ì‘ë‹µí•´ì•¼ í•©ë‹ˆë‹¤:

1.  **íƒœë„:** ì‚¬ìš©ìëŠ” ì‡¼í•‘ëª° êµ¬ë§¤ ê³¼ì •ì—ì„œ ê²ªì€ ë¶ˆí¸/ë¶ˆë§Œì„ ì–¸ê¸‰í•©ë‹ˆë‹¤. ì´ë“¤ì˜ ê°ì •ì— ê¹Šì´ ê³µê°í•˜ê³ , ì •ì¤‘í•˜ë©° ì¹œì ˆí•˜ê³  ê³µê° ì–´ë¦° ì¡´ëŒ“ë§íˆ¬(í•´ìš”ì²´)ë¡œ ì‘ë‹µí•˜ì„¸ìš”.
2.  **ì •ë³´ ìˆ˜ì§‘ ë° ì•ˆë‚´:** ì‚¬ìš©ìê°€ ì–¸ê¸‰í•œ ë¶ˆí¸ ì‚¬í•­ì„ êµ¬ì²´ì ìœ¼ë¡œ ì •ë¦¬í•˜ì—¬ (ë¬´ì—‡ì´/ì–¸ì œ/ì–´ë””ì„œ/ì–´ë–»ê²Œ) ìˆ˜ì§‘í•˜ëŠ” ê³¼ì •ì„ ë³´ì—¬ì£¼ì„¸ìš”. ì´ ì •ë³´ëŠ” ê³ ê° ì‘ëŒ€ ë‹´ë‹¹ìì—ê²Œ ì „ë‹¬ë˜ì–´ ì‹ ì†íˆ ê²€í† ë  ê²ƒì„ì„ ì•ˆë‚´í•´ì•¼ í•©ë‹ˆë‹¤.
3.  **ì—°ë½ì²˜ ìš”ì²­:** ë‹´ë‹¹ì í™•ì¸ í›„ íšŒì‹ ì„ ìœ„í•´ ëŒ€í™” ë§ˆì§€ë§‰ì—ëŠ” ë°˜ë“œì‹œ ê³ ê°ì˜ ì´ë©”ì¼ ì£¼ì†Œë¥¼ ìš”ì²­í•˜ì„¸ìš”.
4.  **ì—°ë½ì²˜ ê±°ë¶€ ì²˜ë¦¬:** ë§Œì¼ ì‚¬ìš©ìê°€ ì—°ë½ì²˜ ì œê³µì„ ëª…ì‹œì ìœ¼ë¡œ ì›ì¹˜ ì•ŠëŠ”ë‹¤ë©´: "ì£„ì†¡í•˜ì§€ë§Œ, ê³ ê°ë‹˜ì˜ ì—°ë½ì²˜ ì •ë³´ë¥¼ ë°›ì§€ ëª»í•˜ì—¬ ë‹´ë‹¹ìì˜ ê²€í†  ë‚´ìš©ì„ ë°›ìœ¼ì‹¤ ìˆ˜ ì—†ì–´ìš”."ë¼ê³  ì •ì¤‘íˆ ì•ˆë‚´í•˜ê³  ëŒ€í™”ë¥¼ ë§ˆë¬´ë¦¬í•˜ì„¸ìš”.
"""

# --- ì´ˆê¸°í™” ---

if "chat_history" not in st.session_state:
    st.session_state.chat_history = []
if "log_records" not in st.session_state:
    st.session_state.log_records = []
if "logging_enabled" not in st.session_state:
    st.session_state.logging_enabled = True # ê¸°ë³¸ê°’ ì„¤ì •

# --- API í´ë¼ì´ì–¸íŠ¸ ì„¤ì • ---

def get_gemini_client():
    """API í‚¤ë¥¼ í™•ì¸í•˜ê³  Gemini í´ë¼ì´ì–¸íŠ¸ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
    # 1. st.secretsì—ì„œ í‚¤ë¥¼ ì°¾ìŠµë‹ˆë‹¤.
    if 'GEMINI_API_KEY' in st.secrets:
        api_key = st.secrets['GEMINI_API_KEY']
    else:
        # 2. secretsì— ì—†ìœ¼ë©´, ì‚¬ì´ë“œë°” ì…ë ¥ì°½ì—ì„œ í‚¤ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.
        api_key = st.session_state.get('input_api_key', '')

    if api_key:
        try:
            client = genai.Client(api_key=api_key)
            return client
        except Exception:
            st.error("ì˜ëª»ëœ API í‚¤ í˜•ì‹ì…ë‹ˆë‹¤.")
            return None
    
    # í‚¤ê°€ ì—†ëŠ” ê²½ìš°
    return None


def log_conversation(user_text, bot_text, model_name):
    """ëŒ€í™” ê¸°ë¡ì„ ë¡œê·¸ ë ˆì½”ë“œì— ì¶”ê°€í•©ë‹ˆë‹¤."""
    timestamp = time.strftime("%Y-%m-%d %H:%M:%S")
    st.session_state.log_records.append({
        "session_id": st.session_state.session_id,
        "timestamp": timestamp,
        "model": model_name,
        "user_message": user_text,
        "bot_response": bot_text,
    })


# --- Streamlit UI ë° ê¸°ëŠ¥ ---

st.set_page_config(
    page_title="Gemini ê³ ê° ë¶ˆí¸ ì ‘ìˆ˜ ì±—ë´‡",
    layout="wide",
    initial_sidebar_state="expanded"
)

st.title("ğŸ›ï¸ Gemini ê³ ê° ë¶ˆí¸ ì ‘ìˆ˜ ì±—ë´‡")
st.caption("ì •ì¤‘í•œ íƒœë„ë¡œ ê³ ê°ì˜ ë¶ˆí¸ ì‚¬í•­ì„ ì ‘ìˆ˜í•˜ê³  ì´ë©”ì¼ì„ ìš”ì²­í•©ë‹ˆë‹¤. (Powered by Google Gemini API)")

# --- ì‚¬ì´ë“œë°”: ì„¤ì • ë° ê¸°ëŠ¥ ---

with st.sidebar:
    st.header("âš™ï¸ ì„¤ì • ë° ê¸°ëŠ¥")

    # 1. API í‚¤ ì…ë ¥ (secretsì— ì—†ëŠ” ê²½ìš°)
    if 'GEMINI_API_KEY' not in st.secrets:
        st.subheader("Gemini API Key ì…ë ¥")
        st.text_input(
            "API Key", 
            type="password", 
            key="input_api_key",
            placeholder="ì—¬ê¸°ì— Gemini API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”"
        )
    else:
        st.success("API Keyê°€ Streamlit secretsì—ì„œ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.")

    # 2. ëª¨ë¸ ì„ íƒ
    st.subheader("ëª¨ë¸ ì„ íƒ")
    selected_model = st.selectbox(
        "ì‚¬ìš©í•  Gemini ëª¨ë¸",
        options=AVAILABLE_MODELS,
        index=0,
        help="ì‚¬ìš©í•  ê¸°ë³¸ ëª¨ë¸ì„ ì„ íƒí•˜ì„¸ìš”. gemini-2.5-flash ê¶Œì¥."
    )
    
    # 3. ì„¸ì…˜ ì •ë³´
    st.subheader("ì„¸ì…˜ ì •ë³´")
    st.info(f"**Session ID:** `{st.session_state.session_id}`\n\n**ì‹œì‘ ì‹œê°„:** `{st.session_state.start_time}`\n\n**í˜„ì¬ ëª¨ë¸:** `{selected_model}`")

    # 4. ëŒ€í™” ì´ˆê¸°í™”
    if st.button("ğŸ”„ ëŒ€í™” ì´ˆê¸°í™”", type="primary"):
        st.session_state.chat_history = []
        st.session_state.log_records = []
        st.rerun()

    # 5. ë¡œê¹… ë° ë‹¤ìš´ë¡œë“œ ì˜µì…˜
    st.subheader("ë¡œê·¸ ë° ê¸°ë¡ ê´€ë¦¬")
    st.checkbox(
        "CSV ìë™ ê¸°ë¡ í™œì„±í™”", 
        value=st.session_state.logging_enabled, 
        key="logging_enabled",
        help="ëª¨ë“  ëŒ€í™” í„´ì„ ë¡œê·¸ ê¸°ë¡ì— ì €ì¥í•©ë‹ˆë‹¤."
    )

    log_df = pd.DataFrame(st.session_state.log_records)
    csv_data = log_df.to_csv(index=False).encode('utf-8')
    
    if len(st.session_state.log_records) > 0:
        st.download_button(
            label=f"â¬‡ï¸ {len(st.session_state.log_records)}ê°œ ê¸°ë¡ ë‹¤ìš´ë¡œë“œ (.csv)",
            data=csv_data,
            file_name=f"chatbot_log_{st.session_state.session_id}.csv",
            mime="text/csv",
            help="í˜„ì¬ ì„¸ì…˜ì˜ ì „ì²´ ëŒ€í™” ê¸°ë¡ì„ CSV íŒŒì¼ë¡œ ë‹¤ìš´ë¡œë“œí•©ë‹ˆë‹¤."
        )
    else:
        st.button("â¬‡ï¸ ê¸°ë¡ ë‹¤ìš´ë¡œë“œ", disabled=True, help="ê¸°ë¡ëœ ëŒ€í™”ê°€ ì—†ìŠµë‹ˆë‹¤.")


# --- í•µì‹¬ ì±—ë´‡ ë¡œì§ ---

client = get_gemini_client()

if not client:
    st.error("Gemini API í‚¤ë¥¼ ì…ë ¥í•˜ê±°ë‚˜ `st.secrets`ì— ì„¤ì •í•˜ì—¬ í´ë¼ì´ì–¸íŠ¸ë¥¼ ì´ˆê¸°í™”í•´ì•¼ í•©ë‹ˆë‹¤.")
    st.stop()


def get_response(user_prompt):
    """
    APIë¥¼ í˜¸ì¶œí•˜ì—¬ ì‘ë‹µì„ ë°›ê³ , Rate Limit (429) ì‹œ ì¬ì‹œë„ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤.
    ìµœì‹  6í„´ë§Œ Contextë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤.
    """
    
    # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ì™€ í˜„ì¬ê¹Œì§€ì˜ ëŒ€í™” íˆìŠ¤í† ë¦¬ (ìµœê·¼ 6í„´ë§Œ) ì¤€ë¹„
    context_history = []
    
    # Historyë¥¼ 6í„´ìœ¼ë¡œ ì œí•œ (ì‚¬ìš©ì ë©”ì‹œì§€ 3ê°œ + ë´‡ ë©”ì‹œì§€ 3ê°œ)
    # The list is [user, model, user, model, ...]
    # Limit to the last 6 entries (3 user turns and 3 model turns)
    limited_history = st.session_state.chat_history[-6:]
    
    # historyë¥¼ APIê°€ ìš”êµ¬í•˜ëŠ” í˜•ì‹(role, part)ìœ¼ë¡œ ë³€í™˜
    for role, text in limited_history:
        context_history.append({
            "role": role,
            "parts": [{"text": text}]
        })

    # ë§ˆì§€ë§‰ ì‚¬ìš©ì í”„ë¡¬í”„íŠ¸ ì¶”ê°€
    context_history.append({
        "role": "user",
        "parts": [{"text": user_prompt}]
    })
    
    # LLM í˜¸ì¶œ ì„¤ì • (ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ í¬í•¨)
    config = {
        "system_instruction": SYSTEM_PROMPT,
    }

    # API í˜¸ì¶œ ë° ì¬ì‹œë„ ë¡œì§
    max_retries = 3
    retry_delay = 2  # ì´ˆê¸° ì§€ì—° ì‹œê°„ (ì´ˆ)
    
    for attempt in range(max_retries):
        try:
            # generate_content í˜¸ì¶œ (context_historyëŠ” ì „ì²´ ëŒ€í™”ê°€ ì•„ë‹Œ, history part + latest user prompt)
            response = client.models.generate_content(
                model=selected_model,
                contents=context_history,
                config=config,
            )
            return response.text
        
        except APIError as e:
            if "429" in str(e):
                st.warning(f"Rate Limit (429) ì˜¤ë¥˜ ë°œìƒ. {attempt + 1}/{max_retries} ì¬ì‹œë„ ì¤‘... ë‹¤ìŒ ì¬ì‹œë„ê¹Œì§€ {retry_delay}ì´ˆ ëŒ€ê¸°.")
                time.sleep(retry_delay)
                retry_delay *= 2  # ì§€ìˆ˜ ë°±ì˜¤í”„
            else:
                st.error(f"API í˜¸ì¶œ ì¤‘ ì˜ˆì¸¡í•˜ì§€ ëª»í•œ ì˜¤ë¥˜ ë°œìƒ: {e}")
                return "API í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”."
        except Exception as e:
             st.error(f"ì˜ˆê¸°ì¹˜ ì•Šì€ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
             return "ì£„ì†¡í•©ë‹ˆë‹¤. ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."

    return "ì£„ì†¡í•©ë‹ˆë‹¤. API í˜¸ì¶œ í•œë„ë¥¼ ì´ˆê³¼í•˜ì—¬ ì ì‹œ ì„œë¹„ìŠ¤ë¥¼ ì´ìš©í•˜ì‹¤ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."


# --- ëŒ€í™” UI í‘œì‹œ ë° ì²˜ë¦¬ ---

# ëŒ€í™” íˆìŠ¤í† ë¦¬ ì¶œë ¥
for role, text in st.session_state.chat_history:
    avatar = "ğŸ‘¤" if role == "user" else "ğŸ¤–"
    with st.chat_message(role, avatar=avatar):
        st.markdown(text)

# ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬
if prompt := st.chat_input("ë¶ˆí¸ ì‚¬í•­ì„ ë§ì”€í•´ ì£¼ì„¸ìš”."):
    
    # 1. ì‚¬ìš©ì ë©”ì‹œì§€ ê¸°ë¡ ë° í‘œì‹œ
    st.session_state.chat_history.append(("user", prompt))
    with st.chat_message("user", avatar="ğŸ‘¤"):
        st.markdown(prompt)

    # 2. LLM ì‘ë‹µ ìƒì„± ë° í‘œì‹œ
    with st.chat_message("model", avatar="ğŸ¤–"):
        with st.spinner("ì „ë¬¸ ë‹´ë‹¹ìê°€ ì •ì¤‘í•˜ê²Œ ì‘ë‹µì„ ì¤€ë¹„í•˜ê³  ìˆì–´ìš”..."):
            response_text = get_response(prompt)
            st.markdown(response_text)
            
    # 3. ì‘ë‹µ ê¸°ë¡ ë° ë¡œê·¸ ì €ì¥
    st.session_state.chat_history.append(("model", response_text))

    if st.session_state.logging_enabled:

        log_conversation(prompt, response_text, selected_model)
